{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "                        AI-DRIVEN LANGUAGE TRANSLATION & VOICE INTERACTION SYSTEM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Project comprises of 3 components:\n",
    "1.Image Language Translation\n",
    "2.Video Language Translation\n",
    "3.Voice Interaction System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import openai\n",
    "from googletrans import Translator\n",
    "from gtts import gTTS\n",
    "import os\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import time\n",
    "from ffpyplayer.player import MediaPlayer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.IMAGE LANGUAGE TRANSLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread(r'D:\\dlproject\\image1.jpg')\n",
    "img\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every new day\n",
      "is a chance to\n",
      "change your life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perform OCR on the image\n",
    "text = pytesseract.image_to_string(img) \n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translated Text:\n",
      "ഓരോ പുതിയ ദിവസവും\n",
      "ഒരു അവസരമാണ്\n",
      "നിങ്ങളുടെ ജീവിതം മാറ്റുക.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the translator\n",
    "translator = Translator()\n",
    "\n",
    "# Translate the extracted text\n",
    "translated_text = translator.translate(text, src='auto', dest='ml')  # Translate to kannada\n",
    "\n",
    "print(\"\\nTranslated Text:\")\n",
    "print(translated_text.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.VIDEO LANGUAGE TRANSLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Spoken Text: focus on what you are really really good at and make that you are strong point because that's what I did as well and I also believe that in life no matter what you do everyday give your 100% because you never know what's coming for you you never know what's the next step right I don't know how irritated came to me\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Performing on video\n",
    "video_path = r'D:\\dlproject\\video3.mp4'\n",
    "audio_path = 'audio.wav'  # Output audio file\n",
    "\n",
    "\n",
    "def PlayVideo(video_path, frame_delay=0.0115):\n",
    "    video=cv2.VideoCapture(video_path)\n",
    "    player = MediaPlayer(video_path)\n",
    "    while True:\n",
    "        grabbed, frame=video.read()\n",
    "        audio_frame, val = player.get_frame()\n",
    "        if not grabbed:\n",
    "            print(\"End of video\")\n",
    "            break\n",
    "        if cv2.waitKey(28) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        if val != 'eof' and audio_frame is not None:\n",
    "            #audio\n",
    "            img, t = audio_frame\n",
    "        # Introduce a delay between frames\n",
    "        time.sleep(frame_delay)\n",
    "             \n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "PlayVideo(video_path, frame_delay=0.0115)\n",
    "\n",
    "video_clip = VideoFileClip(video_path)\n",
    "audio_clip = video_clip.audio\n",
    "audio_clip.write_audiofile(audio_path)\n",
    "\n",
    "#for speech recognition\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile('audio.wav') as source:\n",
    "    audio = recognizer.listen(source)\n",
    "\n",
    "try:\n",
    "    spoken_text = recognizer.recognize_google(audio, language='en')\n",
    "    print(\"Spoken Text:\", spoken_text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results; {0}\".format(e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translated Text:\n",
      "നിങ്ങൾ ശരിക്കും നല്ല കാര്യങ്ങളിൽ ശ്രദ്ധ കേന്ദ്രീകരിക്കുകയും നിങ്ങൾ ശക്തരാണെന്ന് വരുത്തുകയും ചെയ്യുക, കാരണം ഞാനും അതാണ് ചെയ്തത്, ജീവിതത്തിൽ നിങ്ങൾ ദിവസവും എന്ത് ചെയ്താലും നിങ്ങളുടെ 100% നൽകുമെന്ന് ഞാൻ വിശ്വസിക്കുന്നു, കാരണം നിങ്ങൾക്ക് ഒരിക്കലും എന്താണ് സംഭവിക്കുന്നതെന്ന് നിങ്ങൾക്കറിയില്ല.അടുത്ത ഘട്ടം എന്താണെന്ന് അറിയുക, എനിക്ക് എങ്ങനെ പ്രകോപിതനായി എന്ന് എനിക്കറിയില്ല\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = Translator()\n",
    "\n",
    "translated_text = translator.translate(spoken_text, src='en', dest='ml')  # Translate to Malayalam\n",
    "\n",
    "print(\"\\nTranslated Text:\")\n",
    "print(translated_text.text)\n",
    "\n",
    "# Convert the translated text to audio\n",
    "translated_audio = gTTS(text=translated_text.text, lang='ml')  # Assuming the target language is Malayalam\n",
    "translated_audio_path = 'translated_audio.mp3'\n",
    "translated_audio.save(translated_audio_path)\n",
    "\n",
    "# Play the translated audio using the default system audio player\n",
    "os.system(f'start {translated_audio_path}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.VOICE INTERACTION SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak something...\n",
      "You said: who is the first prime minister of India\n",
      "Detected Language: en\n",
      "\n",
      "Translated Text: who is the first prime minister of India\n",
      "Answer: The first Prime Minister of India was Jawaharlal Nehru.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Initialize the translator\n",
    "translator = Translator()\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Capture audio from the microphone\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Speak something...\")\n",
    "    audio = recognizer.listen(source, phrase_time_limit=5)\n",
    "\n",
    "try:\n",
    "    # Recognize speech using Google Web Speech API\n",
    "    spoken_text = recognizer.recognize_google(audio)\n",
    "    \n",
    "\n",
    "    # Detect the language of the spoken text\n",
    "    detected_language = translator.detect(spoken_text).lang\n",
    "    print(\"You said:\", spoken_text)\n",
    "    print(\"Detected Language:\", detected_language)\n",
    "\n",
    "    # Set the target language for translation based on detected language\n",
    "    if detected_language == 'hi':\n",
    "        target_language = 'hi'\n",
    "    else:\n",
    "        target_language = 'en'\n",
    "    \n",
    "\n",
    "    # Translate the spoken text to the specified target language\n",
    "    translated_text = translator.translate(spoken_text, src=detected_language, dest=target_language)\n",
    "    print(\"\\nTranslated Text:\", translated_text.text)\n",
    "\n",
    "    \n",
    "    # Use the translated text as a prompt for GPT-3\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",  # Choose the desired GPT-3 engine\n",
    "        prompt = f\"provide an accurate and one sentence answer for this question in the same language: '{translated_text.text}'\",\n",
    "        max_tokens=200, # Specify the number of tokens for the response\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Print the GPT-3 generated answer\n",
    "    print(\"Answer:\", response.choices[0].text.strip())\n",
    "\n",
    "    tts = gTTS(text=response.choices[0].text.strip(), lang=target_language)\n",
    "    tts.save(\"output.mp3\")\n",
    "\n",
    "    # Play the generated audio file\n",
    "    os.system(\"start output.mp3\")\n",
    "    \n",
    "\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results; {0}\".format(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
